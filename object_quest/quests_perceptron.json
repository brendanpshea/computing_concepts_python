{
  "quests": [
    {
      "title": "Define the Perceptron Class",
      "description": "Write the constructor for the `Perceptron` class. Implement `__init__(self)` with the correct signature and include only `pass` in the body.",
      "success_message": "Good: your Perceptron class exists!",
      "initial_code": "class Perceptron:\n    # TODO: write empty constructor using __init__ with pass\n    pass",
      "test_code": "import unittest\n\nclass TestClassExists(unittest.TestCase):\n    def test_class_definition(self):\n        p = Perceptron()\n        self.assertIsInstance(p, Perceptron, \"Perceptron should be instantiable\")",
      "hints": [
        "Inside the class, write `def __init__(self):`",
        "Use a single `pass` statement in its body so that instantiation does not error"
      ]
    },
    {
      "title": "Initialize Weights and Bias",
      "description": "Inside your `__init__`, assign `self.weights = []` and `self.bias = 0` so that after `p = Perceptron()`, both attributes exist.",
      "success_message": "Weights and bias initialized!",
      "initial_code": "class Perceptron:\n    def __init__(self):\n        # TODO: set up weight vector and bias\n        pass",
      "test_code": "import unittest\n\nclass TestInit(unittest.TestCase):\n    def test_weights_and_bias(self):\n        p = Perceptron()\n        self.assertEqual(p.weights, [], \"Weights should start as empty list\")\n        self.assertEqual(p.bias, 0, \"Bias should start at zero\")",
      "hints": [
        "In `__init__`, write `self.weights = []`",
        "Then write `self.bias = 0`"
      ]
    },
    {
      "title": "Set Learning Rate",
      "description": "Extend `__init__` to accept a `learning_rate: float` parameter (default `0.1`) and store it in `self.learning_rate`.",
      "success_message": "Learning rate set!",
      "initial_code": "class Perceptron:\n    def __init__(self, learning_rate: float = 0.1):\n        self.weights = []\n        self.bias = 0\n        # TODO: store the learning rate for updates\n        pass",
      "test_code": "import unittest\n\nclass TestLearningRate(unittest.TestCase):\n    def test_default_lr(self):\n        p = Perceptron()\n        self.assertEqual(p.learning_rate, 0.1)\n\n    def test_custom_lr(self):\n        p = Perceptron(learning_rate=0.5)\n        self.assertEqual(p.learning_rate, 0.5)",
      "hints": [
        "Add `learning_rate` as a parameter to `__init__` with default `0.1`",
        "Inside `__init__`, assign `self.learning_rate = learning_rate`"
      ]
    },
    {
      "title": "Activation Function",
      "description": "Implement `_activate(self, x: float) -> int` to return `1` if `x >= 0`, otherwise `0`.",
      "success_message": "Activation function works!",
      "initial_code": "class Perceptron:\n    def __init__(self, learning_rate: float = 0.1):\n        self.weights = []\n        self.bias = 0\n        self.learning_rate = learning_rate\n\n    def _activate(self, x: float) -> int:\n        # TODO: threshold at zero\n        pass",
      "test_code": "import unittest\n\nclass TestActivation(unittest.TestCase):\n    def test_activate(self):\n        p = Perceptron()\n        self.assertEqual(p._activate(0.5), 1)\n        self.assertEqual(p._activate(0), 1)\n        self.assertEqual(p._activate(-0.1), 0)",
      "hints": [
        "Use `if x >= 0: return 1`",
        "Otherwise, return `0`"
      ]
    },
    {
      "title": "Predict Method",
      "description": "Add `predict(self, inputs: list) -> int`: compute weighted sum `sum(w*i)` plus `bias`, then return `self._activate(total)`.",
      "success_message": "Predict returns correct labels!",
      "initial_code": "class Perceptron:\n    def __init__(self, learning_rate: float = 0.1):\n        self.weights = []\n        self.bias = 0\n        self.learning_rate = learning_rate\n\n    def _activate(self, x: float) -> int:\n        return 1 if x >= 0 else 0\n\n    def predict(self, inputs: list) -> int:\n        # TODO: compute dot product + bias, then activate\n        pass",
      "test_code": "import unittest\n\nclass TestPredict(unittest.TestCase):\n    def test_simple_predict(self):\n        p = Perceptron()\n        p.weights = [1, -1]\n        p.bias = 0\n        self.assertEqual(p.predict([2, 1]), 1)\n        self.assertEqual(p.predict([1, 2]), 0)",
      "hints": [
        "Compute `total = sum(w * i for w, i in zip(self.weights, inputs)) + self.bias`",
        "Return `self._activate(total)`"
      ]
    },
    {
      "title": "Initialize Weight Vector",
      "description": "Implement `initialize(self, n_features: int)` so that `self.weights` becomes a list of `n_features` zeros.",
      "success_message": "Weights initialized to zeros!",
      "initial_code": "class Perceptron:\n    # ... other methods ...\n\n    def initialize(self, n_features: int):\n        # TODO: set self.weights to [0,0,...]\n        pass",
      "test_code": "import unittest\n\nclass TestInitialize(unittest.TestCase):\n    def test_weights_length(self):\n        p = Perceptron()\n        p.initialize(3)\n        self.assertEqual(p.weights, [0, 0, 0])",
      "hints": [
        "Use `[0] * n_features` to create the zero list"
      ]
    },
    {
      "title": "Perceptron Update Rule",
      "description": "Add `update(self, inputs: list, target: int)`: compute `error = target - self.predict(inputs)`, then update `weights[i] += η * error * inputs[i]` and `bias += η * error`.",
      "success_message": "Update rule implemented!",
      "initial_code": "class Perceptron:\n    # ... other methods ...\n\n    def update(self, inputs: list, target: int):\n        # TODO: apply perceptron learning rule\n        pass",
      "test_code": "import unittest\n\nclass TestUpdate(unittest.TestCase):\n    def test_update(self):\n        p = Perceptron(learning_rate=0.5)\n        p.weights = [0, 0]\n        p.bias = 0\n        p.update([1,1], 1)\n        self.assertEqual(p.weights, [0, 0])\n        self.assertEqual(p.bias, 0)\n        p.update([1,1], 0)\n        self.assertEqual(p.weights, [-0.5, -0.5])\n        self.assertEqual(p.bias, -0.5)",
      "hints": [
        "Compute `error = target - self.predict(inputs)`",
        "Update each weight and bias accordingly"
      ]
    },
    {
      "title": "Train for One Epoch",
      "description": "Implement `train_epoch(self, data: list[list], labels: list[int])` to iterate `for inp, tgt in zip(data, labels): self.update(inp, tgt)`.",
      "success_message": "Training epoch complete!",
      "initial_code": "class Perceptron:\n    # ... other methods ...\n\n    def train_epoch(self, data: list, labels: list):\n        # TODO: train on every sample once\n        pass",
      "test_code": "import unittest\n\nclass TestTrainEpoch(unittest.TestCase):\n    def test_and_gate(self):\n        X = [[0,0],[0,1],[1,0],[1,1]]\n        y = [0,0,0,1]\n        p = Perceptron(learning_rate=1)\n        p.initialize(2)\n        p.train_epoch(X, y)\n        self.assertNotEqual(p.weights, [0,0])",
      "hints": [
        "Loop through `zip(data, labels)` calling `self.update`"
      ]
    },
    {
      "title": "Compute Accuracy",
      "description": "Add `score(self, data: list[list], labels: list[int]) -> float` returning fraction of correct `predict` calls.",
      "success_message": "Accuracy calculation ready!",
      "initial_code": "class Perceptron:\n    # ... other methods ...\n\n    def score(self, data: list, labels: list) -> float:\n        # TODO: return (# correct) / len(labels)\n        pass",
      "test_code": "import unittest\n\nclass TestScore(unittest.TestCase):\n    def test_perfect_score(self):\n        p = Perceptron()\n        p.predict = lambda x: 1\n        X = [[0],[1]]\n        y = [1,1]\n        self.assertEqual(p.score(X, y), 1.0)\n\n    def test_half_score(self):\n        p.predict = lambda x: 1\n        y = [1,0]\n        self.assertEqual(p.score(X, y), 0.5)",
      "hints": [
        "Count correct predictions then divide by total samples"
      ]
    }
  ]
}
